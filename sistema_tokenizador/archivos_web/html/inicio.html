<!--
  Html de página de inicio de sitio público.
  Aplicación web de sistema tokenizador.
  Proyecto Lovelace.
-->

<div
  class="seccion"
  flex="none"
  layout="column">

  <md-content
    class="md-padding">
    <div
      flex="70"
      flex-lg="85"
      flex-md="100"
      flex-sm="100"
      flex-xs="100"
      layout="column">

      <h1>¿Qué es la tokenización?</h1>
      <h2>Primero, ¿qué es un token?</h2>
      <p>
        Antes de definir la <em>tokenización</em>, es menester definir lo que es
        un token: normalmente, se le conoce como un valor representativo de otro
        valor; el concepto de token es ampliamente utilizado en otros contextos,
        y, dependiendo de este, varían sus características. En la criptografía
        (que es el contexto en el que se encuentra este servicio), este
        <em>valor representativo</em> no debe tener una relación directa con el
        valor original; de hecho, que un adversario posea un token no representa
        peligro alguno, pues no es posible, sin los mecanismos de
        detokenización, regresar al valor original. Por lo tanto, un token puede
        ser utilizado para proteger información confidencial.
      </p>

      <h2>Sobre la tokenización</h2>
      <p>
        Con esta definición de un token, se puede definir a la tokenización como
        el proceso en el que se obtiene el valor sustituto. Este paradigma de
        sustituir datos sensibles por datos representativos (y sin valor) es
        relativamente nuevo, pero muy útil al momento de proteger la
        información, pues permite concentrar toda la información valiosa en un
        solo lugar y dejar de preocuparse por protegerla en todos lados (en vez
        de vigilar un castillo, se vigila una habitación).
      </p>
      <p>
        La operación inversa, es decir dado un token, obtener el PAN que le
        corresponde, es llamada <em>detokenización</em>.
      </p>

      <h1>¿Por qué utilizar un servicio de tokenización?</h1>
      <p>
        Desde que el comercio eletrónico comenzó a popularizarse, los fraudes
        relacionados con las tarjetas bancarias y el comercio en línea
        crecieron, pues los sitios de bancarios y de comercion no estaban
        preparados para la demanda y las amenazas de seguridad a las que
        comenzaron a enfrentarse. Por lo tanto, en 2004, fue publicado por
        primera vez un estándar (PCI DSS, respaldado por compañías como VISA y
        MasterCard) donde se dan las guías de seguridad que deberían seguir
        todos aquellos que traten con datos de tarjetas o realicen transacciones
        bancarias.
      </p>
      <p>
        Aunque este estándar no es obligatorio para aquellas entidades que
        realicen menos de 20 000 transacciones en un año; es extremadamente
        recomendable que se sigan la guía para mantener segura la información y
        transacciones.  Empero, satisfacer completamente el estándar es una
        verdadera proeza, cuenta con más de 200 requerimientos para segurar la
        robustez y seguridad del sistema que trata con los datos y pagos con
        tarjetas bancarias.
      </p>
      <p>
        Es aquí donde entran los servicios de tokenización, pues se encargan de
        cumplir con todos los requerimientos y quitarle esa pesada carga para
        que pueda enfocarse en sus actividades sin preocuparse por el estándar y
        sus implementaciones. Obviamente, es muy importante saber cómo es que
        servicio de tokenización está obteniendo los tokens, pues no basta con
        asegurar que son seguros; los servicios deben indicar (y hacer públicos)
        los algoritmos que utilizan para generar los tokens. Por lo tanto, que
        un servicio clame que tiene la mejor manera para generar tokens, pero no
        especifique cómo es que los está obteniendo (o que lo haga de manera
        vaga, por ejemplo, asegurando que sus tokens son obtenidos
        aleatoriamente sin dar más detalles), es inadmisible, pues un buen
        algoritmo tokenizador no depende en absoluto de ser mantenido en
        secreto.
      </p>

      <h1>¿Por qué utilizar ESTE servicio de tokenización?</h1>
      <p>
        A diferencia de otros competidores, nosotros somos transparentes
        respecto a la manera en la que se generan los tokens; actualmente, hay
        cinco algoritmos distintos para obtener tokens y usted puede decidir,
        para cada token, el algoritmo que será utilizado: un poco más adelante
        hay una sección que explica brevemente cada algoritmo y nuestras
        implementaciones son públicas.
      </p>

      <h1>¿Qué es el PCI SSC?</h1>
      <p>
        El <a href="https://www.pcisecuritystandards.org/pci_security/"
        md-colors="{color: 'accent'}">Payment Card Industry Security Standards
        Council (PCI SSC)</a> es una organización internacional encargada de
        estandarizar, desarrollar e informar sobre cómo hacer transacciones
        bancarias seguras.
      </p>
      <p>
        Esta organización desarrolló el PCI Data Security Standard (DSS): un
        estándar en el que se indica la manera de mantener la información
        bancaria segura mediante la implementación de protocolos de seguridad.
      </p>
      <p>
        Es importante resaltar que el PCI SSC ha establecido como requerimiento
        la implementación del PCI DSS solo para aquellas entidades que realizan
        un número de transacciones considerables (20 000 al año).
      </p>

      <h1>Sobre los algoritmos de tokenización</h1>
      <p>
        Nuestro sistema permite seleccionar el algoritmo con el que se desea
        tokenizar un dato. Se tienen dos tipos de algoritmos: los reversibles y
        los irreversibles. La diferencia entre unos y otros radica en la
        operación de detokenización, pues los primeros (los reversibles)
        <em>descifran</em> el token para obtener el PAN; mientras que los
        segundos hacen una consulta a una base de datos para obtener el PAN.
      </p>
      <p>
        Contamos con 2 algoritmos de tokenización reversibles: FFX y BPS, y 3
        algoritmos de tokenización irreversibles: TKR, AHR y DRBG. A
        continuación se encuentra una breve descripción de cada uno.
      </p>

      <div
        layout="row"
        layout-sm="column"
        layout-xs="column">
        <div
          flex="33"
          flex-sm="100"
          flex-xs="100"
          layout="column">
          <md-card>
            <md-card-title>
              <md-card-title-text>
                <span class="md-headline">FFX</span>
                <span class="md-subhead">
                  Format-preserving Feistel-based Encryption
                </span>
              </md-card-title-text>
            </md-card-title>
            <md-card-content>
              <p>
                Este es un cifrado que permite cifrar cadenas de cualquier
                tamaño, compuestas por cualquier tipo de caracteres, el cual es
                usado para tokenizar. Fue publicado por Mihir Bellare, Phillip
                Rogaway y Terence Spies en 2009, aunque en 2016 el National
                Institute of Standards and Technology (NIST) le dio el nombre de
                FF1 a este algoritmo.
              </p>
              <p>
                De forma general, el algoritmo usa redes Feistel junto con
                primitivas criptográficas (función hash o cifrados por bloques)
                adaptadas en la función de ronda de la red para lograr preservar
                el formato del dato dado para tokenizar; esto significa que el
                token tendrá la misma longitud y se mantendrá en el mismo
                dominio que el dato original.
              </p>
              <p>
                Para conocer más sobre este algoritmo revise el siguiente
                artículo: <a md-colors="{color: 'accent'}"
                  href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.304.1736&rep=rep1&type=pdf">
                  The FFX Mode of Operation for Format-PreservingEncryption
                </a>.
              </p>
            </md-card-content>
          </md-card>
          <md-card>
            <md-card-title>
              <md-card-title-text>
                <span class="md-headline">BPS</span>
                <span class="md-subhead">
                  Brier-Peyrin-Stern
                </span>
              </md-card-title-text>
            </md-card-title>
            <md-card-content>
              <p>
                Es un cifrado que preserva el formato usado para tokenizar,
                propuesto por Eric Brier, Thomas Peyrin y Jacques Stern en 2010
                y renombrado por el NIST como FF3.
              </p>
              <p>
                Al igual que FFX, usa redes Feistel y primitivas criptográficas
                para lograr que el token tenga el mismo formato que el dato
                original.
              </p>
              <p>
                Para conocer más sobre este algoritmo revise el siguiente
                artículo: <a md-colors="{color: 'accent'}"
                  href="https://pdfs.semanticscholar.org/0be5/d4c77e333d78ddab5c4bf55d15649a660771.pdf">
                  BPS: a Format-Preserving Encryption Proposal
                </a>.
              </p>
            </md-card-content>
          </md-card>
        </div>
        <div
          flex="33"
          flex-sm="100"
          flex-xs="100"
          layout="column">
          <md-card>
            <md-card-title>
              <md-card-title-text>
                <span class="md-headline">TKR</span>
              </md-card-title-text>
            </md-card-title>
            <md-card-content>
              <p>
                Propuesto por Sandra Díaz Santiago, Lil María Rodríguez
                Henríquez y Debrup Chakraborty en 2016, es un algoritmo que usa
                primitivas criptográficas para generar tokens aleatorios y
                almacenarlos en una base de datos segura para guardar su
                relación con el dato original.
              </p>
              <p>
                Para conocer más sobre este algoritmo revisa el artículo:
                <a md-colors="{color: 'accent'}"
                  href="https://link.springer.com/article/10.1007%2Fs10207-015-0313-x">
                  A cryptographic study of tokenization systems
                </a>.
              </p>
            </md-card-content>
          </md-card>
          <md-card>
            <md-card-title>
              <md-card-title-text>
                <span class="md-headline">AHR</span>
                <span class="md-subhead">
                  Algoritmo Híbrido Reversible
                </span>
              </md-card-title-text>
            </md-card-title>
            <md-card-content>
              <p>
                Algoritmo de tokenización publicado por Riccardo Aragona,
                Riccardo Longo y Massimiliano Sala en 2017.
              </p>
              <p>
                Este se basa en un cifrado de bloques y una caminata cíclica
                para generar tokens que mantengan el formato; los tokens son
                almacenados en una base de datos segura para guardar la relación
                con los datos originales.
              </p>
              <p>
                Para conocer más sobre este algoritmo revise el siguiente
                artículo: <a md-colors="{color: 'accent'}"
                  href="https://link.springer.com/article/10.1007%2Fs00200-017-0313-3">
                  Several proofs of security for a tokenization algorithm
                </a>.
              </p>
            </md-card-content>
          </md-card>
        </div>
        <div
          flex="33"
          flex-sm="100"
          flex-xs="100"
          layout="column">
          <md-card>
            <md-card-title>
              <md-card-title-text>
                <span class="md-headline">DRBG</span>
                <span class="md-subhead">
                  Deterministic Random Bit Generator
                </span>
              </md-card-title-text>
            </md-card-title>
            <md-card-content>
              <p>
                La tokenización por este medio se logra produciendo una cadena
                de bits aleatoria con un DRBG que se interpreta de forma
                especial para que tenga el formato del dato original.
              </p>
              <p>
                El DRGB puede estar basado tanto en funciones hash como en
                cifrados por bloque.
              </p>
              <p>
                Para conocer más sobre este algoritmo revise el siguiente
                artículo: <a md-colors="{color: 'accent'}"
                  href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-90Ar1.pdf">
                  NIST Special Publication 800-90A Revision 1
                </a>.
              </p>
            </md-card-content>
          </md-card>
        </div>
      </div>

      <h1>Una comparación</h1>
      <p>
        En aras de arrojar luz sobre el desempeño de los algoritmos, a
        continuación se encuentran dos gráficas que muestran el tiempo que les
        toma a sendos algotimos realizar el mismo número de tokenizaciones.
        Naturalmente, los algoritmos irreversibles son más lentos, pues deben
        realizar operaciones en la base de datos; por lo que se comparan
        algoritmos reversibles con algoritmos reversibles y algoritmos
        irreversibles con algoritmos irreversibles.
      </p>
      <p>
        En esta primera gráfica se comparan los tiempos de tokenización y
        detokenización de los algoritmos de FFX y BPS mientras el número
        de operaciones se incrementa.
      </p>
      <div class="grafica">
        <img src="estaticos/imagenes/todo_rev.png">
      </div>
      <p>
        Es importante observar que los tiempos de tokenización y detokenización
        son tan parecidos, que sus gráficas se sobreponen completamente.
      </p>
      <p>
        En esta otra se muestra los tiempos de tokenización y detokenización de
        TKR, AHR y DRGB mientras el número de operaciones se incrementa.
      </p>
      <div class="grafica">
        <img src="estaticos/imagenes/todo_irrev.png">
      </div>
      <p>
        Aquí es importante resaltar que, si bien el tiempo de tokenización es
        considerable (comparándolo con los reversibles), el tiempo de
        detokenización es mucho más corto, incluso es menor a los algoritmos
        reversibles.
      </p>
    </div>
  </md-content>
</div>
