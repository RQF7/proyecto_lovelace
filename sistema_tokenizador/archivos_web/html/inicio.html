<!--
  Html de página de inicio de sitio público.
  Aplicación web de sistema tokenizador.
  Proyecto Lovelace.
-->

<div
  class="seccion"
  flex="none"
  layout="column">

  <h3>¿Qué es la tokenización?</h3>

  <h4>Primero, ¿qué un token?</h4>
  <p>
    Para comenzar a definir la <em>tokenización</em>, es menester definir antes
    lo que es un token: normalmente, se le conoce como un valor representativo
    de otro valor; el concepto de token es ampliamente utilizado en otros
    contextos, y, dependiendo de este, varían sus características. En la
    criptografía (que es el contexto en el que se encuentra este servicio),
    este <em>valor representativo</em> no debe tener una relación directa con el
    valor original; de hecho, que un adversario posea un token no representa
    peligro alguno, pues no es posible, sin los mecanismos de detokenización,
    regresar al valor original. Por lo tanto, un token puede ser utilizado para
    proteger información confidencial.
  </p>

  <h4>Sobre la tokenización</h4>
  <p>
    Con esta definición de un token, se puede definir a la tokenización como el
    proceso en el que se obtiene el valor sustituto. Este paradigma de sustituir
    datos sensibles por datos representativos (y sin valor) es relativamente
    nuevo, pero muy útil al momento de proteger la información, pues permite
    concentrar toda la información valiosa en un solo lugar y dejar de
    preocuparse por protegerla en todos lados (en vez de vigilar un castillo,
    se vigila una habitación).
  </p>
  <p>
    La operación inversa, es decir dado un token, obtener el PAN que le
    corresponde, es llamada <em>detokenización</em>. 
  </p>
  <p>
    La tokenización ha ido ganando terreno y cada vez hay más maneras de generar
    tokens (generando números pseudoaleatorios, con cifradores que preservan el
    formato, etcétera). Es importante resaltar que la manera en la que un
    servicio tokenizador genera sus tokens debe ser expuesta claramente, pues la
    seguridad de un algoritmo tokenizador jamás debería depender de su secreto.
  </p>

  <h3>¿Por qué usar nuestro servicio de tokenización?</h3>
  <p>
    Nuestro servicio de tokenización le permitirá despreocuparse, en cierta
    medida, de la tediosa y complicada protección de los datos bancarios
    sensibles de su sistema, pues nosotros nos encargaremos de esta parte.

    Además, tenemos varios algoritmos tokenizadores disponibles y usted podrá
    escoger, para cada PAN, cuál es el algoritmo que desea utilizar (aquí puede
    encontrar más información sobre los algoritmos tokenizadores disponibles).
  </p>
  <p>
    Entre las ventajas que obtienes al usar nuestro servicio están:
  </p>
  <md-list flex>
    <md-list-item class="md-1-line">
      <i class="material-icons md-avatar">done</i>
      <div class="md-list-item-text">
        <p>
          Mantener la seguridad de su sistema cumpliendo con el estándar de
          seguridad del PCI SSC.
        </p>
      </div>
    </md-list-item>
    <md-list-item class="md-1-line">
      <i class="material-icons md-avatar">done</i>
      <div class="md-list-item-text">
        <p>
          Salvaguardar la confidencialidad de datos sensibles por medio de la
          tokenización.
        </p>
      </div>
    </md-list-item>
    <md-list-item class="md-1-line">
      <i class="material-icons md-avatar">done</i>
      <div class="md-list-item-text">
        <p>
          Elegir el algoritmo con el que desea tokenizar. Se encuentran
          disponibles FFX, BPS, TKR, AHR y DRGB.
        </p>
      </div>
    </md-list-item>
  </md-list>

  <h3>¿Qué es el PCI SSC?</h3>
  <p>
    El <a href="https://www.pcisecuritystandards.org/pci_security/">Payment
    Card Industry Security Standards Council (PCI SSC)</a> es una organización
    internacional encargada de estandarizar, desarrollar e informar sobre
    cómo hacer transacciones bancarias seguras.
  </p>
  <p>
    Esta organización desarrolló el PCI Data Security Standard (DSS): un
    estándar en el que se indica la manera de mantener la información bancaria
    segura mediante la implementación de protocolos de seguridad.
  </p>
  <p>
    Es importante resaltar que el PCI SSC ha establecido como requerimiento la
    implementación del PCI DSS solo para aquellas entidades que realizan un
    número de transacciones considerables (20 000 al año).
  </p>

  <h3>Sobre los algoritmos de tokenización</h3>
  <p>
    Nuestro sistema permite seleccionar el algoritmo con el que se desea
    tokenizar un dato. Se tienen dos tipos de algoritmos: los reversibles y los
    irreversibles. La diferencia entre unos y otros radica en la operación de
    detokenización, pues los primeros (los reversibles) <em>descifran</em> el
    token para obtener el PAN; mientras que los segundos hacen una consulta a
    una base de datos para obtener el PAN.
  </p>
  <p>
    Contamos con 2 algoritmos de tokenización reversibles: FFX y BPS, y 3
    algoritmos de tokenización irreversibles: TKR, AHR y DRBG. A continuación
    se encuentra una breve descripción de cada uno.
  </p>

  <div>
    <h4>FFX (Format-preserving Feistel-based Encryption) o FF1</h4>
    <p>
      Este es un cifrado que permite cifrar cadenas de cualquier tamaño,
      compuestas por cualquier tipo de caracteres, el cual es usado para
      tokenizar. Fue publicado por Mihir Bellare, Phillip Rogaway y
      Terence Spies en 2009, aunque en 2016 el National Institute of
      Standards and Technology (NIST) le dio el nombre de FF1 a este
      algoritmo.
    </p>
    <p>
      De forma general, el algoritmo usa redes Feistel junto con primitivas
      criptográficas (función hash o cifrados por bloques) adaptadas
      en la función de ronda de la red para lograr preservar el formato
      del dato dado para tokenizar; esto significa que el token tendrá
      la misma longitud y se mantendrá en el mismo dominio que el dato
      original.
    </p>
    <p>
      Para conocer más sobre este algoritmo revise el siguiente artículo:
      <a
        href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.304.1736&rep=rep1&type=pdf">
        The FFX Mode of Operation for Format-PreservingEncryption
      </a>
    </p>
  </div>
  <div>
    <h4>BPS (Brier-Peyrin-Stern) o FF3</h4>
    <p>
      Es un cifrado que preserva el formato usado para tokenizar,
      propuesto por Eric Brier, Thomas Peyrin y Jacques Stern en 2010 y
      renombrado por el NIST como FF3.
    </p>
    <p>
      Al igual que FFX, usa redes Feistel y primitivas criptográficas para
      lograr que el token tenga el mismo formato que el dato original.
    </p>
    <p>
      Para conocer más sobre este algoritmo revise el siguiente artículo:
      <a
        href="https://pdfs.semanticscholar.org/0be5/d4c77e333d78ddab5c4bf55d15649a660771.pdf">
        BPS: a Format-Preserving Encryption Proposal
      </a>
    </p>
  </div>
  <div>
    <h4>TKR</h4>
    <p>
      Propuesto por Sandra Díaz Santiago, Lil María Rodríguez Henríquez y
      Debrup Chakraborty en 2016, es un algoritmo que usa primitivas
      criptográficas para generar tokens aleatorios y almacenarlos en una
      base de datos segura para guardar su relación con el dato original.
    </p>
    <p>
      Para conocer más sobre este algoritmo revisa el artículo:
      <a href="https://link.springer.com/article/10.1007%2Fs10207-015-0313-x">
        A cryptographic study of tokenization systems
      </a>
    </p>
  </div>
  <div>
    <h4>AHR (Algoritmo Híbrido Reversible)</h4>
    <p>
      Algoritmo de tokenización publicado por Riccardo Aragona, Riccardo
      Longo y Massimiliano Sala en 2017.
    </p>
    <p>
      Este se basa en un cifrado de bloques y una caminata cíclica para
      generar tokens que mantengan el formato; los tokens son almacenados en una
      base de datos segura para guardar la relación con los datos originales.
    </p>
    <p>
      Para conocer más sobre este algoritmo revise el siguiente artículo:
      <a href="https://link.springer.com/article/10.1007%2Fs00200-017-0313-3">
        Several proofs of security for a tokenization algorithm
      </a>
    </p>
  </div>
  <div>
    <h4>
      Tokenización por medio de un DRGB
      (Deterministic Random Bit Generator)
    </h4>
    <p>
      La tokenización por este medio se logra produciendo una cadena de
      bits aleatoria con un DRBG que se interpreta de forma especial para
      que tenga el formato del dato original.
    </p>
    <p>
      El DRGB puede estar basado tanto en funciones hash como en cifrados
      por bloque.
    </p>
  </div>

  <h3>Una comparación</h3>
  <p>
    En aras de arrojar luz sobre el desempeño de los algoritmos, a continuación
    se encuentran dos gráficas que muestran el tiempo que les toma a sendos
    algotimos realizar el mismo número de tokenizaciones. Naturalmente, los
    algoritmos irreversibles son más lentos, pues deben realizar operaciones
    en la base de datos; por lo que se comparan algoritmos reversibles con
    algoritmos reversibles y algoritmos irreversibles con algoritmos
    irreversibles.
  </p>
  <p>
    En esta primera gráfica se comparan los tiempos de tokenización y
    detokenización de los algoritmos de FFX y BPS mientras el número
    de operaciones se incrementa.
  </p>
  <div class="grafica">
    <img src="estaticos/imagenes/todo_rev.png">
  </div>
  <p>
    Es importante observar que los tiempos de tokenización y detokenización son
    tan parecidos, que sus gráficas se sobreponen completamente.
  </p>
  <p>
    En esta otra se muestra los tiempos de tokenización y detokenización de
    TKR, AHR y DRGB mientras el número de operaciones se incrementa.
  </p>
  <div class="grafica">
    <img src="estaticos/imagenes/todo_irrev.png">
  </div>
  <p>
    Aquí es importante resaltar que, si bien el tiempo de tokenización es
    considerable (comparándolo con los reversibles), el tiempo de detokenización
    es mucho más pequeño, incluso es menor a los algoritmos reversibles.
  </p>
</div>
